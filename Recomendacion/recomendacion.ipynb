{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistema de Recomendación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que toda la data es consumible por la API, está lista para consumir por los departamentos de Analytics y Machine Learning, y nuestro EDA nos permite entender bien los datos a los que tenemos acceso, es hora de entrenar nuestro modelo de machine learning para armar un sistema de recomendación de películas. El EDA debería incluir gráficas interesantes para extraer datos, como por ejemplo una nube de palabras con las palabras más frecuentes en los títulos de las películas. Éste consiste en recomendar películas a los usuarios basándose en películas similares, por lo que se debe encontrar la similitud de puntuación entre esa película y el resto de películas, se ordenarán según el score de similaridad y devolverá una lista de Python con 5 valores, cada uno siendo el string del nombre de las películas con mayor puntaje, en orden descendente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def recomendacion( titulo ): Se ingresa el nombre de una película y te recomienda las similares en una lista de 5 valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que tenemos que hacer primero es importar las librerías de scikit-learn. En este caso tenemos TfidfVectorizer que convierte una colección de documentos sin procesar en una matriz y a cosine_similarity para poder utilizar su fórmula matemática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('C:\\\\Users\\\\User\\\\OneDrive\\\\Escritorio\\\\Proyecto Final Individual I\\\\data.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Recomendaciones para 'jumanji':\n",
      "1. Toy Story (Puntaje: 7.7)\n",
      "2. Grumpier Old Men (Puntaje: 6.5)\n",
      "3. Waiting to Exhale (Puntaje: 6.1)\n",
      "4. Father of the Bride Part II (Puntaje: 5.7)\n",
      "5. Heat (Puntaje: 7.7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def normalizar_texto(texto):\n",
    "    return unidecode(str(texto).lower().strip())\n",
    "\n",
    "def combinar_features(row):\n",
    "    genres = row['genre_name'] if isinstance(row['genre_name'], str) else ''\n",
    "    companies = row['company_names'] if isinstance(row['company_names'], str) else ''\n",
    "    return f\"{genres} {companies}\".strip()\n",
    "\n",
    "def recomendar_peliculas(titulo, data, n_recomendaciones=5):\n",
    "    # Verificar columnas necesarias\n",
    "    required_columns = ['title', 'genre_name', 'company_names', 'release_year', 'vote_average']\n",
    "    for col in required_columns:\n",
    "        if col not in data.columns:\n",
    "            raise ValueError(f\"La columna '{col}' no está presente en el DataFrame.\")\n",
    "    \n",
    "    # Asegurar que las columnas numéricas sean del tipo correcto\n",
    "    data['release_year'] = pd.to_numeric(data['release_year'], errors='coerce')\n",
    "    data['vote_average'] = pd.to_numeric(data['vote_average'], errors='coerce')\n",
    "    \n",
    "    # Normalizar los títulos en el dataset\n",
    "    data['title_normalized'] = data['title'].apply(normalizar_texto)\n",
    "    \n",
    "    # Preprocesamiento\n",
    "    data['combined_features'] = data.apply(combinar_features, axis=1)\n",
    "    \n",
    "    # Verificar si hay contenido en combined_features\n",
    "    if data['combined_features'].str.strip().str.len().sum() == 0:\n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "        data['combined_features'] = data['title_normalized']\n",
    "    \n",
    "    # Similitud del coseno\n",
    "    tfidf = TfidfVectorizer(stop_words='english', min_df=1, max_df=0.9)\n",
    "    tfidf_matrix = tfidf.fit_transform(data['combined_features'])\n",
    "    \n",
    "    # Verificar si se generó algún término\n",
    "    if tfidf_matrix.shape[1] == 0:\n",
    "        print(\"No se pudieron extraer características significativas de los datos.\")\n",
    "        return []\n",
    "    \n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    \n",
    "    # Normalizar el título de búsqueda\n",
    "    titulo_normalizado = normalizar_texto(titulo)\n",
    "    \n",
    "    # Obtener índice de la película\n",
    "    idx = data.index[data['title_normalized'] == titulo_normalizado].tolist()\n",
    "    if not idx:\n",
    "        print(f\"La película '{titulo}' no se encuentra en la base de datos.\")\n",
    "        return []\n",
    "    idx = idx[0]\n",
    "    \n",
    "    # Calcular puntuaciones de similitud\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:n_recomendaciones+1]\n",
    "    \n",
    "    # Obtener índices de películas recomendadas por similitud del coseno\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    \n",
    "    # Si no hay suficientes recomendaciones, usar KNN\n",
    "    if len(movie_indices) < n_recomendaciones:\n",
    "        # Preparar características para KNN\n",
    "        genres = pd.get_dummies(data['genre_name'].fillna('').str.split().apply(pd.Series).stack()).groupby(level=0).sum()\n",
    "        companies = pd.get_dummies(data['company_names'].fillna('').str.split().apply(pd.Series).stack()).groupby(level=0).sum()\n",
    "        \n",
    "        # Normalizar el año y el puntaje\n",
    "        scaler = MinMaxScaler()\n",
    "        years = scaler.fit_transform(data['release_year'].values.reshape(-1, 1))\n",
    "        ratings = scaler.fit_transform(data['vote_average'].fillna(data['vote_average'].mean()).values.reshape(-1, 1))\n",
    "        \n",
    "        # Combinar características\n",
    "        features = np.hstack((genres.values, companies.values, years, ratings))\n",
    "        \n",
    "        # Entrenar KNN\n",
    "        knn = NearestNeighbors(n_neighbors=n_recomendaciones, metric='euclidean')\n",
    "        knn.fit(features)\n",
    "        \n",
    "        # Encontrar vecinos más cercanos\n",
    "        _, indices = knn.kneighbors(features[idx].reshape(1, -1))\n",
    "        \n",
    "        # Añadir índices faltantes\n",
    "        movie_indices.extend([i for i in indices[0] if i not in movie_indices])\n",
    "        movie_indices = movie_indices[:n_recomendaciones]\n",
    "    \n",
    "    # Devolver las películas recomendadas con sus puntajes\n",
    "    recomendaciones = data[['title', 'vote_average']].iloc[movie_indices]\n",
    "    return recomendaciones.values.tolist()\n",
    "\n",
    "# Ejemplo de uso con input del usuario\n",
    "titulo_pelicula = input(\"Dime una pelícua y te recomendaré 5 películas\")\n",
    "recomendaciones = recomendar_peliculas(titulo_pelicula, data)\n",
    "if recomendaciones:\n",
    "    print(f\"\\nRecomendaciones para '{titulo_pelicula}':\")\n",
    "    for i, (pelicula, puntaje) in enumerate(recomendaciones, 1):\n",
    "        print(f\"{i}. {pelicula} (Puntaje: {puntaje:.1f})\")\n",
    "else:\n",
    "    print(\"No se pudieron generar recomendaciones.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
